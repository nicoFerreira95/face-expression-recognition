{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2c68b2e-4ba7-4180-97a9-90c943bd9567",
      "metadata": {
        "id": "e2c68b2e-4ba7-4180-97a9-90c943bd9567"
      },
      "source": [
        "# Face recognition modeling\n",
        "\n",
        "In the following notebook, I will fit a variety of models to do image classification.\n",
        "\n",
        "**Selected models**:\n",
        "* Convolutional Neural Network (CNN),\n",
        "* Hugging face image classification transformer,\n",
        "* ViTs\n",
        "\n",
        "All of them will be fit in order to compare their performance and offer benchmarks.\n",
        "\n",
        "**Hyperparameter tuning**:\n",
        "* steps per epoch,\n",
        "* epoch,\n",
        "* learning rate,\n",
        "* and other parameters\n",
        "\n",
        "Will be fit using RandomSearch (NOT GridSearch :) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4a59e65b-0b58-4020-a61b-154e66c7bd82",
      "metadata": {
        "id": "4a59e65b-0b58-4020-a61b-154e66c7bd82"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import models, layers\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, MaxPooling2D, Dropout\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting Google Drive storage"
      ],
      "metadata": {
        "id": "Mh2_qqzV5VOk"
      },
      "id": "Mh2_qqzV5VOk"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67kWkqbV5UfE",
        "outputId": "9040a6b0-bdeb-4503-8154-5cb9552312e5"
      },
      "id": "67kWkqbV5UfE",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (48, 48, 1)  # Shape of input images\n",
        "num_classes = 7  # Number of classes for classification"
      ],
      "metadata": {
        "id": "IBGq_WIG1KMn"
      },
      "id": "IBGq_WIG1KMn",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading npy array files"
      ],
      "metadata": {
        "id": "z2KF9Np56bzf"
      },
      "id": "z2KF9Np56bzf"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0f87e41d-79af-497f-ba86-2b48142ebc7e",
      "metadata": {
        "id": "0f87e41d-79af-497f-ba86-2b48142ebc7e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def read_arrays_from_drive(folder_path, imgs_filename, lbls_filename):\n",
        "    \"\"\"\n",
        "    Reads the imgs and lbls arrays from a Google Drive folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder in Google Drive.\n",
        "        imgs_filename (str): The filename for the imgs array.\n",
        "        lbls_filename (str): The filename for the lbls array.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the imgs and lbls arrays.\n",
        "    \"\"\"\n",
        "    # Load the .npy files from the specified folder in Google Drive\n",
        "    imgs = np.load(f\"{folder_path}/{imgs_filename}\")\n",
        "    lbls = np.load(f\"{folder_path}/{lbls_filename}\")\n",
        "\n",
        "    return imgs, lbls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "eb05b3d8-0008-420e-8ca8-3cee703abc94",
      "metadata": {
        "id": "eb05b3d8-0008-420e-8ca8-3cee703abc94"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/drive/MyDrive/ML Project/data\"\n",
        "train_imgs_filename = \"train_imgs.npy\"\n",
        "train_lbls_filename = \"train_lbls.npy\"\n",
        "test_imgs_filename = \"test_imgs.npy\"\n",
        "test_lbls_filename = \"test_lbls.npy\"\n",
        "val_imgs_filename = \"val_imgs.npy\"\n",
        "val_lbls_filename = \"val_lbls.npy\"\n",
        "\n",
        "train_imgs, train_lbls = read_arrays_from_drive(folder_path, train_imgs_filename, train_lbls_filename)\n",
        "test_imgs, test_lbls = read_arrays_from_drive(folder_path, test_imgs_filename, test_lbls_filename)\n",
        "val_imgs, val_lbls = read_arrays_from_drive(folder_path, val_imgs_filename, val_lbls_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa215d44-fb84-4c9e-af58-84c0ab471705",
      "metadata": {
        "id": "fa215d44-fb84-4c9e-af58-84c0ab471705"
      },
      "source": [
        "Print shape of all files to make sure they are correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4d81402d-b1ff-49da-bcb1-a27a2d596d85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d81402d-b1ff-49da-bcb1-a27a2d596d85",
        "outputId": "435b5a8f-62fb-49e8-d715-2bb29f43aa79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (28709, 48, 48, 1)\n",
            "Shape of testing data: (3589, 48, 48, 1)\n",
            "Shape of validation data: (3589, 48, 48, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of training data: {np.shape(train_imgs)}')\n",
        "print(f'Shape of testing data: {np.shape(test_imgs)}')\n",
        "print(f'Shape of validation data: {np.shape(val_imgs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe13807-8dd0-4333-a288-5826ff66e733",
      "metadata": {
        "id": "7fe13807-8dd0-4333-a288-5826ff66e733"
      },
      "source": [
        "## Model fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d5ba12f-1436-4c49-a095-b58e06f5b79c",
      "metadata": {
        "id": "2d5ba12f-1436-4c49-a095-b58e06f5b79c"
      },
      "source": [
        "#### 1. CNN - LeNet architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390f2146-6f76-4756-a212-ba35f5adc74a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390f2146-6f76-4756-a212-ba35f5adc74a",
        "outputId": "f22a431f-e9fa-4dfd-b915-e33296adb3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 44, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 22, 22, 6)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 18, 18, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 9, 9, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1296)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               155640    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 595       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,971\n",
            "Trainable params: 168,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# defining LeNet architecture\n",
        "def create_lenet_model(input_shape, num_classes):\n",
        "    model_lenet = Sequential()\n",
        "    \n",
        "    # Convolutional layers\n",
        "    model_lenet.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
        "    model_lenet.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model_lenet.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "    model_lenet.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # Flatten the 3D output to 1D\n",
        "    model_lenet.add(Flatten())\n",
        "    \n",
        "    # Fully connected layers\n",
        "    model_lenet.add(Dense(120, activation='relu'))\n",
        "    model_lenet.add(Dense(84, activation='relu'))\n",
        "    \n",
        "    # Output layer\n",
        "    model_lenet.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    return model_lenet\n",
        "\n",
        "# Create an instance of the LeNet model\n",
        "input_shape = (48, 48, 1)  # Input shape of your images\n",
        "num_classes = 7  # Number of classes for classification\n",
        "model_lenet = create_lenet_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model_lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_lenet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f297aec-d40d-42f6-8bc6-25b06be426b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f297aec-d40d-42f6-8bc6-25b06be426b4",
        "outputId": "db9f532d-0c2a-4dae-ba69-06b45e252368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 17s 6ms/step - loss: 1.6530 - accuracy: 0.3467 - val_loss: 1.5348 - val_accuracy: 0.4035\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 5s 6ms/step - loss: 1.4920 - accuracy: 0.4220 - val_loss: 1.4517 - val_accuracy: 0.4322\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 4s 5ms/step - loss: 1.4059 - accuracy: 0.4549 - val_loss: 1.3993 - val_accuracy: 0.4539\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 5s 6ms/step - loss: 1.3354 - accuracy: 0.4861 - val_loss: 1.3532 - val_accuracy: 0.4756\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 5s 5ms/step - loss: 1.2673 - accuracy: 0.5122 - val_loss: 1.3831 - val_accuracy: 0.4806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9bad1f0f70>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Training the model, and validating\n",
        "model_lenet.fit(train_imgs, train_lbls, \n",
        "          epochs=5, batch_size=32, \n",
        "          validation_data=(val_imgs, val_lbls), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k39zoSHH_VZl"
      },
      "id": "k39zoSHH_VZl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rA-CdJH4AF_A"
      },
      "id": "rA-CdJH4AF_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8md75aLnAGRa"
      },
      "id": "8md75aLnAGRa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. CNN - ZF Net"
      ],
      "metadata": {
        "id": "hbsaDQu9AIGf"
      },
      "id": "hbsaDQu9AIGf"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_zf_net(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Creates a ZF Net CNN model.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input images (e.g., (height, width, channels)).\n",
        "        num_classes (int): The number of classes for classification.\n",
        "\n",
        "    Returns:\n",
        "        keras.models.Sequential: The ZF Net CNN model.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(Conv2D(96, (7, 7), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(Conv2D(256, (5, 5), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Convolutional Layer 3\n",
        "    model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # Convolutional Layer 4\n",
        "    model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # Convolutional Layer 5\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully Connected Layer 1\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Fully Connected Layer 2\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "nUJdNd7nAGof"
      },
      "id": "nUJdNd7nAGof",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the ZF Net model\n",
        "input_shape = (48, 48, 1)  # Input shape of your images\n",
        "num_classes = 7  # Number of classes for classification\n",
        "model_zf = create_zf_net(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model_zf.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_zf.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3rHvBoCAG1X",
        "outputId": "46daf5fe-8aca-42f0-8c7c-2c80b3f4c25d"
      },
      "id": "F3rHvBoCAG1X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 42, 42, 96)        4800      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 21, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 21, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 11, 11, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,279,879\n",
            "Trainable params: 58,279,879\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model"
      ],
      "metadata": {
        "id": "JBxRWl7uHgCy"
      },
      "id": "JBxRWl7uHgCy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model, and validating\n",
        "model_zf.fit(train_imgs, train_lbls, \n",
        "          epochs=5, batch_size=32, \n",
        "          validation_data=(val_imgs, val_lbls), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WknkMNRtASXO",
        "outputId": "538cfa77-d706-490b-97f5-3bdccadad25a"
      },
      "id": "WknkMNRtASXO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 35s 31ms/step - loss: 1.8187 - accuracy: 0.2501 - val_loss: 1.8196 - val_accuracy: 0.2449\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 28s 31ms/step - loss: 1.8132 - accuracy: 0.2513 - val_loss: 1.8159 - val_accuracy: 0.2449\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 28s 32ms/step - loss: 1.8125 - accuracy: 0.2513 - val_loss: 1.8154 - val_accuracy: 0.2449\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 28s 32ms/step - loss: 1.8121 - accuracy: 0.2513 - val_loss: 1.8156 - val_accuracy: 0.2449\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 29s 32ms/step - loss: 1.8119 - accuracy: 0.2513 - val_loss: 1.8166 - val_accuracy: 0.2449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ba0099960>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_zf.save('/content/drive/MyDrive/ML Project/data/zf_model.h5')"
      ],
      "metadata": {
        "id": "e2zitm2fASr6"
      },
      "id": "e2zitm2fASr6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. CNN - ResNet"
      ],
      "metadata": {
        "id": "P2GGvmRuF3qR"
      },
      "id": "P2GGvmRuF3qR"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, Flatten, Dense, Add\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def residual_block(input_tensor, filters, strides=(1, 1), use_projection=False):\n",
        "    \"\"\"\n",
        "    Creates a residual block for the ResNet architecture.\n",
        "\n",
        "    Args:\n",
        "        input_tensor (keras.layers.Layer): The input tensor.\n",
        "        filters (int): The number of filters for the convolutional layers.\n",
        "        strides (tuple): The strides for the convolutional layers.\n",
        "        use_projection (bool): Whether to use projection shortcut.\n",
        "\n",
        "    Returns:\n",
        "        keras.layers.Layer: The output tensor of the residual block.\n",
        "    \"\"\"\n",
        "    # Shortcut path\n",
        "    shortcut = input_tensor\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Projection shortcut\n",
        "    if use_projection:\n",
        "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add shortcut to main path\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "def create_resnet_model(input_shape, num_classes):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, filters=64, strides=(1, 1), use_projection=False)\n",
        "    x = residual_block(x, filters=64, strides=(1, 1), use_projection=False)\n",
        "    x = residual_block(x, filters=128, strides=(2, 2), use_projection=True)\n",
        "    x = residual_block(x, filters=128, strides=(1, 1), use_projection=False)\n",
        "    x = residual_block(x, filters=256, strides=(2, 2), use_projection=True)\n",
        "    x = residual_block(x, filters=256, strides=(1, 1), use_projection=False)\n",
        "    \n",
        "    # Use GlobalAveragePooling2D instead of AveragePooling2D\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hZvzsQjKChC2"
      },
      "id": "hZvzsQjKChC2",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "cmKQm7xKHb01"
      },
      "id": "cmKQm7xKHb01"
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (48, 48, 1)  # Shape of input images\n",
        "num_classes = 7  # Number of classes for classification\n",
        "\n",
        "model_resnet = create_resnet_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_resnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFtXkrNPHZdI",
        "outputId": "acc148b7-9ce7-4f12-cf3c-ff59e993e8db"
      },
      "id": "LFtXkrNPHZdI",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 24, 24, 64)   3200        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 24, 24, 64)  256         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 24, 24, 64)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 12, 12, 64)   0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 12, 12, 64)   36928       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 12, 12, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 12, 12, 64)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 12, 12, 64)   36928       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 12, 12, 64)  256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 12, 12, 64)   0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 12, 12, 64)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 12, 12, 64)   36928       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 12, 12, 64)  256         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 12, 12, 64)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 12, 12, 64)   36928       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 12, 12, 64)  256         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 12, 12, 64)   0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 12, 12, 64)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 6, 6, 128)    73856       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 6, 6, 128)   512         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 6, 6, 128)    0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 6, 6, 128)    147584      ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 6, 6, 128)    8320        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 6, 6, 128)   512         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 6, 6, 128)   512         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 6, 6, 128)    0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 6, 6, 128)    0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 6, 6, 128)    147584      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 6, 6, 128)   512         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 6, 6, 128)    0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 6, 6, 128)    147584      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 6, 6, 128)   512         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 6, 6, 128)    0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 6, 6, 128)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 3, 3, 256)    295168      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 3, 3, 256)    0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 3, 3, 256)    590080      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 3, 3, 256)    33024       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 3, 3, 256)    0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 3, 3, 256)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 3, 3, 256)    590080      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 3, 3, 256)    0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 3, 3, 256)    590080      ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 3, 3, 256)    0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 3, 3, 256)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['activation_12[0][0]']          \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 256)          0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 7)            1799        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,785,031\n",
            "Trainable params: 2,780,551\n",
            "Non-trainable params: 4,480\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model"
      ],
      "metadata": {
        "id": "b0xdgBjFHvIy"
      },
      "id": "b0xdgBjFHvIy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model, and validating\n",
        "model_resnet.fit(train_imgs, train_lbls, \n",
        "          epochs=5, batch_size=32, \n",
        "          validation_data=(val_imgs, val_lbls), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixfrXp7ZHvhY",
        "outputId": "b660882d-f0a0-42f5-c400-fad07e5e8d48"
      },
      "id": "ixfrXp7ZHvhY",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 36s 15ms/step - loss: 1.9194 - accuracy: 0.4182 - val_loss: 2.0784 - val_accuracy: 0.3589\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 12s 14ms/step - loss: 1.5995 - accuracy: 0.5063 - val_loss: 1.6383 - val_accuracy: 0.4723\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 13s 14ms/step - loss: 1.4433 - accuracy: 0.5538 - val_loss: 1.7656 - val_accuracy: 0.3898\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 13s 14ms/step - loss: 1.3486 - accuracy: 0.5856 - val_loss: 1.4627 - val_accuracy: 0.5383\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 12s 14ms/step - loss: 1.2806 - accuracy: 0.6195 - val_loss: 1.4957 - val_accuracy: 0.5403\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7fcc072a70>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model output"
      ],
      "metadata": {
        "id": "0YGF-ThTXsqd"
      },
      "id": "0YGF-ThTXsqd"
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.save('/content/drive/MyDrive/ML Project/data/resnet_model.h5')"
      ],
      "metadata": {
        "id": "Q5o2LmJmXv8g"
      },
      "id": "Q5o2LmJmXv8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet as a baseline model\n",
        "### Hyperparameter tuning\n",
        "I will now shift the focus to hdo some hyperaparameter tuning on the ResNet model and train the CNN with more epochs and steps_per_epoch."
      ],
      "metadata": {
        "id": "rDgvdAcYcDOq"
      },
      "id": "rDgvdAcYcDOq"
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install keras-tuner"
      ],
      "metadata": {
        "id": "pulg15YUe0WC"
      },
      "id": "pulg15YUe0WC",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastunner import RandomSearch\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def build_model(hp):\n",
        "    model_resnet = create_resnet_model(input_shape, num_classes)\n",
        "    \n",
        "    # Tune the learning rate for the optimizer \n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "    \n",
        "    model_resnet.compile(optimizer=Adam(learning_rate = hp_learning_rate), \n",
        "                         loss='categorical_crossentropy', \n",
        "                         metrics=['accuracy'])\n",
        "    \n",
        "    return model_resnet\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='random_search',\n",
        "    project_name='ImageClassification')\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(train_imgs, train_lbls, \n",
        "             epochs=5, \n",
        "             validation_data=(val_imgs, val_lbls))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "CDMx0XK0b7Gf",
        "outputId": "8531e12d-f690-416f-a9a8-a55054325181"
      },
      "id": "CDMx0XK0b7Gf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4d1d30f04928>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_resnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_resnet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_tunner'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/ML Project/data/best_resnet_01.h5')"
      ],
      "metadata": {
        "id": "1at48t2AfaSm"
      },
      "id": "1at48t2AfaSm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning Trial 2.\n",
        "Now I will experiment with different parameters and different number of epochs"
      ],
      "metadata": {
        "id": "QGtQwDCVkaFY"
      },
      "id": "QGtQwDCVkaFY"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras_tuner import HyperParameters\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "def residual_block(input_tensor, filters, strides=(1, 1), activation='relu'):\n",
        "    shortcut = input_tensor\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Projection shortcut if necessary\n",
        "    if input_tensor.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add shortcut to main path\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model(hp):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    activation = hp.Choice('activation', ['relu', 'elu', 'sigmoid'])\n",
        "    \n",
        "    x = Conv2D(\n",
        "        hp.Int('filters_initial', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=(7, 7), \n",
        "        strides=(2, 2), \n",
        "        padding='same', \n",
        "        kernel_initializer='he_normal', \n",
        "        kernel_regularizer=l2(1e-4),\n",
        "        activation=activation\n",
        "    )(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    for i in range(hp.Int('n_layers', 2, 5)):\n",
        "        x = residual_block(\n",
        "            x, \n",
        "            filters=hp.Int('filters_' + str(i), min_value=32, max_value=256, step=32), \n",
        "            strides=(1, 1), \n",
        "            activation=activation\n",
        "        )\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            hp.Float(\n",
        "                'learning_rate',\n",
        "                min_value=1e-5,\n",
        "                max_value=1e-2,\n",
        "                sampling='LOG',\n",
        "                default=1e-3\n",
        "            )\n",
        "        ), \n",
        "        loss='categorical_crossentropy', \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='random_search',\n",
        "    project_name='image_classification'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuhTW8XNj5YU",
        "outputId": "9f4b360e-3a0c-4eca-a8bd-79d6f91eacec"
      },
      "id": "OuhTW8XNj5YU",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu', 'sigmoid'], 'ordered': False}\n",
            "filters_initial (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "n_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "filters_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "filters_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "learning_rate (Float)\n",
            "{'default': 0.001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    train_imgs, \n",
        "    train_lbls, \n",
        "    epochs=20, \n",
        "    validation_data=(val_imgs, val_lbls)\n",
        ")"
      ],
      "metadata": {
        "id": "KZQ6O-uVoSM-"
      },
      "id": "KZQ6O-uVoSM-",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/ML Project/data/best_resnet_hptuning_02.h5')"
      ],
      "metadata": {
        "id": "YwdJVIVJqbiL"
      },
      "id": "YwdJVIVJqbiL",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "best_resnet_hptuning = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "best_resnet_hptuning.fit(\n",
        "    train_imgs, \n",
        "    train_lbls, \n",
        "    epochs=20, \n",
        "    batch_size=32, \n",
        "    validation_data=(val_imgs, val_lbls)\n",
        ")"
      ],
      "metadata": {
        "id": "5Mweyb4gwA1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f763a517-9f0a-4f94-8ac2-492601abc35d"
      },
      "id": "5Mweyb4gwA1N",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "898/898 [==============================] - 19s 19ms/step - loss: 1.9620 - accuracy: 0.4136 - val_loss: 1.8496 - val_accuracy: 0.4558\n",
            "Epoch 2/20\n",
            "898/898 [==============================] - 17s 19ms/step - loss: 1.7306 - accuracy: 0.5018 - val_loss: 1.7612 - val_accuracy: 0.4873\n",
            "Epoch 3/20\n",
            "898/898 [==============================] - 15s 17ms/step - loss: 1.6200 - accuracy: 0.5329 - val_loss: 1.9644 - val_accuracy: 0.4104\n",
            "Epoch 4/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.5320 - accuracy: 0.5593 - val_loss: 1.6942 - val_accuracy: 0.5121\n",
            "Epoch 5/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.4656 - accuracy: 0.5752 - val_loss: 1.7666 - val_accuracy: 0.4634\n",
            "Epoch 6/20\n",
            "898/898 [==============================] - 17s 19ms/step - loss: 1.4064 - accuracy: 0.5923 - val_loss: 1.8474 - val_accuracy: 0.4283\n",
            "Epoch 7/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.3469 - accuracy: 0.6109 - val_loss: 1.6082 - val_accuracy: 0.5202\n",
            "Epoch 8/20\n",
            "898/898 [==============================] - 16s 17ms/step - loss: 1.2933 - accuracy: 0.6254 - val_loss: 1.6102 - val_accuracy: 0.5358\n",
            "Epoch 9/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.2379 - accuracy: 0.6462 - val_loss: 1.4067 - val_accuracy: 0.5795\n",
            "Epoch 10/20\n",
            "898/898 [==============================] - 17s 18ms/step - loss: 1.1847 - accuracy: 0.6642 - val_loss: 1.4976 - val_accuracy: 0.5567\n",
            "Epoch 11/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.1372 - accuracy: 0.6834 - val_loss: 1.4366 - val_accuracy: 0.5801\n",
            "Epoch 12/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.0757 - accuracy: 0.7034 - val_loss: 1.5706 - val_accuracy: 0.5389\n",
            "Epoch 13/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 1.0291 - accuracy: 0.7173 - val_loss: 1.4664 - val_accuracy: 0.5862\n",
            "Epoch 14/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 0.9726 - accuracy: 0.7425 - val_loss: 1.6732 - val_accuracy: 0.5614\n",
            "Epoch 15/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 0.9016 - accuracy: 0.7707 - val_loss: 1.8174 - val_accuracy: 0.5372\n",
            "Epoch 16/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 0.8417 - accuracy: 0.7920 - val_loss: 1.8906 - val_accuracy: 0.5626\n",
            "Epoch 17/20\n",
            "898/898 [==============================] - 16s 17ms/step - loss: 0.7921 - accuracy: 0.8123 - val_loss: 1.7163 - val_accuracy: 0.5784\n",
            "Epoch 18/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 0.7306 - accuracy: 0.8347 - val_loss: 1.8532 - val_accuracy: 0.5475\n",
            "Epoch 19/20\n",
            "898/898 [==============================] - 16s 18ms/step - loss: 0.6772 - accuracy: 0.8541 - val_loss: 1.8673 - val_accuracy: 0.5628\n",
            "Epoch 20/20\n",
            "898/898 [==============================] - 16s 17ms/step - loss: 0.6377 - accuracy: 0.8761 - val_loss: 1.9620 - val_accuracy: 0.5759\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f3ac67e20>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V89E5Cf_wF53"
      },
      "id": "V89E5Cf_wF53",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-8.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2d5ba12f-1436-4c49-a095-b58e06f5b79c",
        "hbsaDQu9AIGf"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}