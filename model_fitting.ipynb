{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2c68b2e-4ba7-4180-97a9-90c943bd9567",
      "metadata": {
        "id": "e2c68b2e-4ba7-4180-97a9-90c943bd9567"
      },
      "source": [
        "# Face recognition modeling\n",
        "\n",
        "In the following notebook, I will fit a variety of models to do image classification.\n",
        "\n",
        "**Selected models**:\n",
        "* Convolutional Neural Network (CNN),\n",
        "* Hugging face image classification transformer,\n",
        "* ViTs\n",
        "\n",
        "All of them will be fit in order to compare their performance and offer benchmarks.\n",
        "\n",
        "**Hyperparameter tuning**:\n",
        "* steps per epoch,\n",
        "* epoch,\n",
        "* learning rate,\n",
        "* and other parameters\n",
        "\n",
        "Will be fit using RandomSearch (NOT GridSearch :) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a59e65b-0b58-4020-a61b-154e66c7bd82",
      "metadata": {
        "id": "4a59e65b-0b58-4020-a61b-154e66c7bd82"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import models, layers\n",
        "import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, MaxPooling2D, Dropout\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting Google Drive storage"
      ],
      "metadata": {
        "id": "Mh2_qqzV5VOk"
      },
      "id": "Mh2_qqzV5VOk"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67kWkqbV5UfE",
        "outputId": "7b54dd12-8a30-4ec6-8511-46351587081a"
      },
      "id": "67kWkqbV5UfE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading npy array files"
      ],
      "metadata": {
        "id": "z2KF9Np56bzf"
      },
      "id": "z2KF9Np56bzf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f87e41d-79af-497f-ba86-2b48142ebc7e",
      "metadata": {
        "id": "0f87e41d-79af-497f-ba86-2b48142ebc7e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def read_arrays_from_drive(folder_path, imgs_filename, lbls_filename):\n",
        "    \"\"\"\n",
        "    Reads the imgs and lbls arrays from a Google Drive folder.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder in Google Drive.\n",
        "        imgs_filename (str): The filename for the imgs array.\n",
        "        lbls_filename (str): The filename for the lbls array.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the imgs and lbls arrays.\n",
        "    \"\"\"\n",
        "    # Load the .npy files from the specified folder in Google Drive\n",
        "    imgs = np.load(f\"{folder_path}/{imgs_filename}\")\n",
        "    lbls = np.load(f\"{folder_path}/{lbls_filename}\")\n",
        "\n",
        "    return imgs, lbls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb05b3d8-0008-420e-8ca8-3cee703abc94",
      "metadata": {
        "id": "eb05b3d8-0008-420e-8ca8-3cee703abc94"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/drive/MyDrive/ML Project/data\"\n",
        "train_imgs_filename = \"train_imgs.npy\"\n",
        "train_lbls_filename = \"train_lbls.npy\"\n",
        "test_imgs_filename = \"test_imgs.npy\"\n",
        "test_lbls_filename = \"test_lbls.npy\"\n",
        "val_imgs_filename = \"val_imgs.npy\"\n",
        "val_lbls_filename = \"val_lbls.npy\"\n",
        "\n",
        "train_imgs, train_lbls = read_arrays_from_drive(folder_path, train_imgs_filename, train_lbls_filename)\n",
        "test_imgs, test_lbls = read_arrays_from_drive(folder_path, test_imgs_filename, test_lbls_filename)\n",
        "val_imgs, val_lbls = read_arrays_from_drive(folder_path, val_imgs_filename, val_lbls_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa215d44-fb84-4c9e-af58-84c0ab471705",
      "metadata": {
        "id": "fa215d44-fb84-4c9e-af58-84c0ab471705"
      },
      "source": [
        "Print shape of all files to make sure they are correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d81402d-b1ff-49da-bcb1-a27a2d596d85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d81402d-b1ff-49da-bcb1-a27a2d596d85",
        "outputId": "3ad154d2-babf-4535-875a-3a90bf2146f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (28709, 48, 48, 1)\n",
            "Shape of testing data: (3589, 48, 48, 1)\n",
            "Shape of validation data: (3589, 48, 48, 1)\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of training data: {np.shape(train_imgs)}')\n",
        "print(f'Shape of testing data: {np.shape(test_imgs)}')\n",
        "print(f'Shape of validation data: {np.shape(val_imgs)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe13807-8dd0-4333-a288-5826ff66e733",
      "metadata": {
        "id": "7fe13807-8dd0-4333-a288-5826ff66e733"
      },
      "source": [
        "## Model fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d5ba12f-1436-4c49-a095-b58e06f5b79c",
      "metadata": {
        "id": "2d5ba12f-1436-4c49-a095-b58e06f5b79c"
      },
      "source": [
        "#### 1. CNN - LeNet architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390f2146-6f76-4756-a212-ba35f5adc74a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390f2146-6f76-4756-a212-ba35f5adc74a",
        "outputId": "c84ef131-be76-4bdf-b976-539d39dc4c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 44, 44, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 22, 22, 6)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 18, 18, 16)        2416      \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 9, 9, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1296)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               155640    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 595       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,971\n",
            "Trainable params: 168,971\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# defining LeNet architecture\n",
        "def create_lenet_model(input_shape, num_classes):\n",
        "    model_lenet = Sequential()\n",
        "    \n",
        "    # Convolutional layers\n",
        "    model_lenet.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
        "    model_lenet.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    model_lenet.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "    model_lenet.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # Flatten the 3D output to 1D\n",
        "    model_lenet.add(Flatten())\n",
        "    \n",
        "    # Fully connected layers\n",
        "    model_lenet.add(Dense(120, activation='relu'))\n",
        "    model_lenet.add(Dense(84, activation='relu'))\n",
        "    \n",
        "    # Output layer\n",
        "    model_lenet.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    return model_lenet\n",
        "\n",
        "# Create an instance of the LeNet model\n",
        "input_shape = (48, 48, 1)  # Input shape of your images\n",
        "num_classes = 7  # Number of classes for classification\n",
        "model_lenet = create_lenet_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model_lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_lenet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f297aec-d40d-42f6-8bc6-25b06be426b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f297aec-d40d-42f6-8bc6-25b06be426b4",
        "outputId": "db9f532d-0c2a-4dae-ba69-06b45e252368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 17s 6ms/step - loss: 1.6530 - accuracy: 0.3467 - val_loss: 1.5348 - val_accuracy: 0.4035\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 5s 6ms/step - loss: 1.4920 - accuracy: 0.4220 - val_loss: 1.4517 - val_accuracy: 0.4322\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 4s 5ms/step - loss: 1.4059 - accuracy: 0.4549 - val_loss: 1.3993 - val_accuracy: 0.4539\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 5s 6ms/step - loss: 1.3354 - accuracy: 0.4861 - val_loss: 1.3532 - val_accuracy: 0.4756\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 5s 5ms/step - loss: 1.2673 - accuracy: 0.5122 - val_loss: 1.3831 - val_accuracy: 0.4806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9bad1f0f70>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Training the model, and validating\n",
        "model_lenet.fit(train_imgs, train_lbls, \n",
        "          epochs=5, batch_size=32, \n",
        "          validation_data=(val_imgs, val_lbls), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k39zoSHH_VZl"
      },
      "id": "k39zoSHH_VZl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rA-CdJH4AF_A"
      },
      "id": "rA-CdJH4AF_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8md75aLnAGRa"
      },
      "id": "8md75aLnAGRa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. CNN - ZF Net"
      ],
      "metadata": {
        "id": "hbsaDQu9AIGf"
      },
      "id": "hbsaDQu9AIGf"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_zf_net(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Creates a ZF Net CNN model.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input images (e.g., (height, width, channels)).\n",
        "        num_classes (int): The number of classes for classification.\n",
        "\n",
        "    Returns:\n",
        "        keras.models.Sequential: The ZF Net CNN model.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(Conv2D(96, (7, 7), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(Conv2D(256, (5, 5), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Convolutional Layer 3\n",
        "    model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # Convolutional Layer 4\n",
        "    model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
        "\n",
        "    # Convolutional Layer 5\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully Connected Layer 1\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Fully Connected Layer 2\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "nUJdNd7nAGof"
      },
      "id": "nUJdNd7nAGof",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the ZF Net model\n",
        "input_shape = (48, 48, 1)  # Input shape of your images\n",
        "num_classes = 7  # Number of classes for classification\n",
        "model_zf = create_zf_net(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model_zf.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_zf.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3rHvBoCAG1X",
        "outputId": "46daf5fe-8aca-42f0-8c7c-2c80b3f4c25d"
      },
      "id": "F3rHvBoCAG1X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 42, 42, 96)        4800      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 21, 21, 96)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 21, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 11, 11, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 11, 11, 384)       1327488   \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 11, 11, 256)       884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              37752832  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,279,879\n",
            "Trainable params: 58,279,879\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model"
      ],
      "metadata": {
        "id": "JBxRWl7uHgCy"
      },
      "id": "JBxRWl7uHgCy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model, and validating\n",
        "model_zf.fit(train_imgs, train_lbls, \n",
        "          epochs=5, batch_size=32, \n",
        "          validation_data=(val_imgs, val_lbls), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WknkMNRtASXO",
        "outputId": "538cfa77-d706-490b-97f5-3bdccadad25a"
      },
      "id": "WknkMNRtASXO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 35s 31ms/step - loss: 1.8187 - accuracy: 0.2501 - val_loss: 1.8196 - val_accuracy: 0.2449\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 28s 31ms/step - loss: 1.8132 - accuracy: 0.2513 - val_loss: 1.8159 - val_accuracy: 0.2449\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 28s 32ms/step - loss: 1.8125 - accuracy: 0.2513 - val_loss: 1.8154 - val_accuracy: 0.2449\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 28s 32ms/step - loss: 1.8121 - accuracy: 0.2513 - val_loss: 1.8156 - val_accuracy: 0.2449\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 29s 32ms/step - loss: 1.8119 - accuracy: 0.2513 - val_loss: 1.8166 - val_accuracy: 0.2449\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ba0099960>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_zf.save('/content/drive/MyDrive/ML Project/data/zf_model.h5')"
      ],
      "metadata": {
        "id": "e2zitm2fASr6"
      },
      "id": "e2zitm2fASr6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. CNN - ResNet"
      ],
      "metadata": {
        "id": "P2GGvmRuF3qR"
      },
      "id": "P2GGvmRuF3qR"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, Flatten, Dense, Add\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def residual_block(input_tensor, filters, strides=(1, 1), use_projection=False):\n",
        "    \"\"\"\n",
        "    Creates a residual block for the ResNet architecture.\n",
        "\n",
        "    Args:\n",
        "        input_tensor (keras.layers.Layer): The input tensor.\n",
        "        filters (int): The number of filters for the convolutional layers.\n",
        "        strides (tuple): The strides for the convolutional layers.\n",
        "        use_projection (bool): Whether to use projection shortcut.\n",
        "\n",
        "    Returns:\n",
        "        keras.layers.Layer: The output tensor of the residual block.\n",
        "    \"\"\"\n",
        "    # Shortcut path\n",
        "    shortcut = input_tensor\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Projection shortcut\n",
        "    if use_projection:\n",
        "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add shortcut to main path\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "def create_resnet_model(input_shape, num_classes):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, filters=64, strides=(1, 1), use_projection=False)\n",
        "    x = residual_block(x, filters=64, strides=(1, 1), use_projection=False)\n",
        "    x = residual_block(x, filters=128, strides=(2, 2), use_projection=True)\n",
        "    x = residual_block(x, filters=128, strides=(1, 1), use_projection=False)\n",
        "    x = residual_block(x, filters=256, strides=(2, 2), use_projection=True)\n",
        "    x = residual_block(x, filters=256, strides=(1, 1), use_projection=False)\n",
        "    \n",
        "    # Use GlobalAveragePooling2D instead of AveragePooling2D\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "hZvzsQjKChC2"
      },
      "id": "hZvzsQjKChC2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "cmKQm7xKHb01"
      },
      "id": "cmKQm7xKHb01"
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (48, 48, 1)  # Shape of input images\n",
        "num_classes = 7  # Number of classes for classification\n",
        "\n",
        "model_resnet = create_resnet_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model_resnet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFtXkrNPHZdI",
        "outputId": "cf7593f0-d800-4334-f56c-20ed70cb909a"
      },
      "id": "LFtXkrNPHZdI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 24, 24, 64)   3200        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 24, 24, 64)  256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 64)  0           ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 12, 12, 64)   36928       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 12, 12, 64)  256         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 12, 12, 64)   36928       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 12, 12, 64)  256         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 12, 12, 64)   0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 12, 12, 64)   0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 12, 12, 64)   36928       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 12, 12, 64)  256         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 12, 12, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 12, 12, 64)   36928       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 12, 12, 64)  256         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 12, 12, 64)   0           ['batch_normalization_19[0][0]', \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 12, 12, 64)   0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 6, 6, 128)    73856       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 6, 6, 128)   512         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 6, 6, 128)    147584      ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 6, 6, 128)    8320        ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 6, 6, 128)   512         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 6, 6, 128)   512         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 6, 6, 128)    0           ['batch_normalization_21[0][0]', \n",
            "                                                                  'batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 6, 6, 128)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 6, 6, 128)    147584      ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 6, 6, 128)   512         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 6, 6, 128)    0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 6, 6, 128)    147584      ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 6, 6, 128)   512         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 6, 6, 128)    0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 6, 6, 128)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 3, 3, 256)    295168      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 3, 3, 256)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 3, 3, 256)    590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 3, 3, 256)    33024       ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 3, 3, 256)    0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 3, 3, 256)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 3, 3, 256)    590080      ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 3, 3, 256)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 3, 3, 256)    590080      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 3, 3, 256)   1024        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 3, 3, 256)    0           ['batch_normalization_29[0][0]', \n",
            "                                                                  'activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 3, 3, 256)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 256)         0           ['activation_25[0][0]']          \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 256)          0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 7)            1799        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,785,031\n",
            "Trainable params: 2,780,551\n",
            "Non-trainable params: 4,480\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model"
      ],
      "metadata": {
        "id": "b0xdgBjFHvIy"
      },
      "id": "b0xdgBjFHvIy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model, and validating\n",
        "model_resnet.fit(train_imgs, train_lbls, \n",
        "          epochs=5, batch_size=32, \n",
        "          validation_data=(val_imgs, val_lbls), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixfrXp7ZHvhY",
        "outputId": "77cb90bf-4c9c-4167-a26b-dcb89708da6f"
      },
      "id": "ixfrXp7ZHvhY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "898/898 [==============================] - 37s 16ms/step - loss: 1.9153 - accuracy: 0.4170 - val_loss: 2.7414 - val_accuracy: 0.3190\n",
            "Epoch 2/5\n",
            "898/898 [==============================] - 14s 15ms/step - loss: 1.5940 - accuracy: 0.5123 - val_loss: 1.8899 - val_accuracy: 0.4673\n",
            "Epoch 3/5\n",
            "898/898 [==============================] - 13s 15ms/step - loss: 1.4445 - accuracy: 0.5559 - val_loss: 1.4754 - val_accuracy: 0.5352\n",
            "Epoch 4/5\n",
            "898/898 [==============================] - 13s 15ms/step - loss: 1.3547 - accuracy: 0.5880 - val_loss: 1.4635 - val_accuracy: 0.5492\n",
            "Epoch 5/5\n",
            "898/898 [==============================] - 13s 15ms/step - loss: 1.2830 - accuracy: 0.6246 - val_loss: 1.6857 - val_accuracy: 0.4765\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd95998ed40>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model output"
      ],
      "metadata": {
        "id": "0YGF-ThTXsqd"
      },
      "id": "0YGF-ThTXsqd"
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet.save('/content/drive/MyDrive/ML Project/data/resnet_model.h5')"
      ],
      "metadata": {
        "id": "Q5o2LmJmXv8g"
      },
      "id": "Q5o2LmJmXv8g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet as a baseline model\n",
        "### Hyperparameter tuning\n",
        "I will now shift the focus to hdo some hyperaparameter tuning on the ResNet model and train the CNN with more epochs and steps_per_epoch."
      ],
      "metadata": {
        "id": "rDgvdAcYcDOq"
      },
      "id": "rDgvdAcYcDOq"
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install keras-tuner"
      ],
      "metadata": {
        "id": "pulg15YUe0WC"
      },
      "id": "pulg15YUe0WC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import RandomSearch\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def build_model(hp):\n",
        "    model_resnet = create_resnet_model(input_shape, num_classes)\n",
        "    \n",
        "    # Tune the learning rate for the optimizer \n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "    \n",
        "    model_resnet.compile(optimizer=Adam(learning_rate = hp_learning_rate), \n",
        "                         loss='categorical_crossentropy', \n",
        "                         metrics=['accuracy'])\n",
        "    \n",
        "    return model_resnet\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='random_search',\n",
        "    project_name='ImageClassification')\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(train_imgs, train_lbls, \n",
        "             epochs=5, \n",
        "             validation_data=(val_imgs, val_lbls))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDMx0XK0b7Gf",
        "outputId": "64470c37-9eb3-49e5-bf1e-997c75170921"
      },
      "id": "CDMx0XK0b7Gf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 04m 16s]\n",
            "val_accuracy: 0.5202006101608276\n",
            "\n",
            "Best val_accuracy So Far: 0.5202006101608276\n",
            "Total elapsed time: 00h 11m 41s\n",
            "\n",
            "The hyperparameter search is complete. The optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/ML Project/data/best_resnet_01.h5')"
      ],
      "metadata": {
        "id": "1at48t2AfaSm"
      },
      "id": "1at48t2AfaSm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning Trial 2.\n",
        "Now I will experiment with different parameters and different number of epochs"
      ],
      "metadata": {
        "id": "QGtQwDCVkaFY"
      },
      "id": "QGtQwDCVkaFY"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from kerastuner import HyperParameters\n",
        "\n",
        "def residual_block(input_tensor, filters, strides=(1, 1), activation='relu'):\n",
        "    shortcut = input_tensor\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Projection shortcut if necessary\n",
        "    if input_tensor.shape[-1] != filters:\n",
        "        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "        shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    # Add shortcut to main path\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation(activation)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_model(hp):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "    activation = hp.Choice('activation', ['relu', 'elu', 'sigmoid'])\n",
        "    \n",
        "    x = Conv2D(\n",
        "        hp.Int('filters_initial', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=(7, 7), \n",
        "        strides=(2, 2), \n",
        "        padding='same', \n",
        "        kernel_initializer='he_normal', \n",
        "        kernel_regularizer=l2(1e-4),\n",
        "        activation=activation\n",
        "    )(input_tensor)\n",
        "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "    \n",
        "    for i in range(hp.Int('n_layers', 2, 5)):\n",
        "        x = residual_block(\n",
        "            x, \n",
        "            filters=hp.Int('filters_' + str(i), min_value=32, max_value=256, step=32), \n",
        "            strides=(1, 1), \n",
        "            activation=activation\n",
        "        )\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Flatten()(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            hp.Float(\n",
        "                'learning_rate',\n",
        "                min_value=1e-5,\n",
        "                max_value=1e-2,\n",
        "                sampling='LOG',\n",
        "                default=1e-3\n",
        "            )\n",
        "        ), \n",
        "        loss='categorical_crossentropy', \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='random_search',\n",
        "    project_name='image_classification'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuhTW8XNj5YU",
        "outputId": "da35f75d-bb27-4664-81c4-f9b38fc5f85f"
      },
      "id": "OuhTW8XNj5YU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 6\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu', 'sigmoid'], 'ordered': False}\n",
            "filters_initial (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "n_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
            "filters_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "filters_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
            "learning_rate (Float)\n",
            "{'default': 0.001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    train_imgs, \n",
        "    train_lbls, \n",
        "    epochs=20, \n",
        "    validation_data=(val_imgs, val_lbls)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZQ6O-uVoSM-",
        "outputId": "e5299ca6-7c9a-41ff-ffed-f06903123b0a"
      },
      "id": "KZQ6O-uVoSM-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 13m 12s]\n",
            "val_accuracy: 0.5035757422447205\n",
            "\n",
            "Best val_accuracy So Far: 0.5035757422447205\n",
            "Total elapsed time: 00h 13m 12s\n",
            "\n",
            "Search: Running Trial #4\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "relu              |relu              |activation\n",
            "32                |64                |filters_initial\n",
            "2                 |2                 |n_layers\n",
            "224               |256               |filters_0\n",
            "96                |256               |filters_1\n",
            "0.00012434        |0.006244          |learning_rate\n",
            "\n",
            "Epoch 1/20\n",
            "898/898 [==============================] - 12s 11ms/step - loss: 1.8524 - accuracy: 0.3434 - val_loss: 1.7132 - val_accuracy: 0.4090\n",
            "Epoch 2/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.6382 - accuracy: 0.4455 - val_loss: 1.6883 - val_accuracy: 0.4338\n",
            "Epoch 3/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.5355 - accuracy: 0.4878 - val_loss: 1.8791 - val_accuracy: 0.3349\n",
            "Epoch 4/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.4610 - accuracy: 0.5161 - val_loss: 1.6241 - val_accuracy: 0.4489\n",
            "Epoch 5/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.4000 - accuracy: 0.5415 - val_loss: 1.5586 - val_accuracy: 0.4673\n",
            "Epoch 6/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.3436 - accuracy: 0.5596 - val_loss: 1.5066 - val_accuracy: 0.5052\n",
            "Epoch 7/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.2869 - accuracy: 0.5846 - val_loss: 1.4463 - val_accuracy: 0.5079\n",
            "Epoch 8/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.2302 - accuracy: 0.6062 - val_loss: 1.7699 - val_accuracy: 0.4338\n",
            "Epoch 9/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.1776 - accuracy: 0.6269 - val_loss: 1.5504 - val_accuracy: 0.4854\n",
            "Epoch 10/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.1150 - accuracy: 0.6495 - val_loss: 1.6036 - val_accuracy: 0.4695\n",
            "Epoch 11/20\n",
            "898/898 [==============================] - 8s 9ms/step - loss: 1.0522 - accuracy: 0.6757 - val_loss: 2.1431 - val_accuracy: 0.3984\n",
            "Epoch 12/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9860 - accuracy: 0.6995 - val_loss: 1.6158 - val_accuracy: 0.4965\n",
            "Epoch 13/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9134 - accuracy: 0.7338 - val_loss: 1.6487 - val_accuracy: 0.4996\n",
            "Epoch 14/20\n",
            "898/898 [==============================] - 8s 9ms/step - loss: 0.8378 - accuracy: 0.7657 - val_loss: 2.0096 - val_accuracy: 0.4015\n",
            "Epoch 15/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7666 - accuracy: 0.7911 - val_loss: 1.7561 - val_accuracy: 0.5015\n",
            "Epoch 16/20\n",
            "898/898 [==============================] - 9s 9ms/step - loss: 0.6951 - accuracy: 0.8229 - val_loss: 2.1850 - val_accuracy: 0.4823\n",
            "Epoch 17/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.6203 - accuracy: 0.8508 - val_loss: 1.7173 - val_accuracy: 0.5255\n",
            "Epoch 18/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5537 - accuracy: 0.8754 - val_loss: 2.2846 - val_accuracy: 0.4218\n",
            "Epoch 19/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.4933 - accuracy: 0.8962 - val_loss: 1.9713 - val_accuracy: 0.4923\n",
            "Epoch 20/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.4345 - accuracy: 0.9214 - val_loss: 1.9082 - val_accuracy: 0.5052\n",
            "Epoch 1/20\n",
            "898/898 [==============================] - 10s 10ms/step - loss: 1.8478 - accuracy: 0.3461 - val_loss: 1.7522 - val_accuracy: 0.4023\n",
            "Epoch 2/20\n",
            "898/898 [==============================] - 8s 9ms/step - loss: 1.6455 - accuracy: 0.4466 - val_loss: 1.6195 - val_accuracy: 0.4500\n",
            "Epoch 3/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.5345 - accuracy: 0.4907 - val_loss: 1.5952 - val_accuracy: 0.4611\n",
            "Epoch 4/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.4557 - accuracy: 0.5198 - val_loss: 1.5248 - val_accuracy: 0.4990\n",
            "Epoch 5/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.3897 - accuracy: 0.5433 - val_loss: 1.4937 - val_accuracy: 0.5013\n",
            "Epoch 6/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.3263 - accuracy: 0.5698 - val_loss: 2.0833 - val_accuracy: 0.3129\n",
            "Epoch 7/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.2686 - accuracy: 0.5922 - val_loss: 1.5865 - val_accuracy: 0.4826\n",
            "Epoch 8/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.2048 - accuracy: 0.6174 - val_loss: 1.4458 - val_accuracy: 0.5160\n",
            "Epoch 9/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.1470 - accuracy: 0.6395 - val_loss: 1.5324 - val_accuracy: 0.4999\n",
            "Epoch 10/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.0782 - accuracy: 0.6676 - val_loss: 1.3998 - val_accuracy: 0.5361\n",
            "Epoch 11/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.0053 - accuracy: 0.6992 - val_loss: 2.2685 - val_accuracy: 0.3580\n",
            "Epoch 12/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.9307 - accuracy: 0.7286 - val_loss: 1.8641 - val_accuracy: 0.4099\n",
            "Epoch 13/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.8568 - accuracy: 0.7584 - val_loss: 1.7030 - val_accuracy: 0.4940\n",
            "Epoch 14/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7791 - accuracy: 0.7904 - val_loss: 1.4962 - val_accuracy: 0.5311\n",
            "Epoch 15/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.7042 - accuracy: 0.8187 - val_loss: 1.8795 - val_accuracy: 0.4561\n",
            "Epoch 16/20\n",
            "898/898 [==============================] - 8s 9ms/step - loss: 0.6329 - accuracy: 0.8478 - val_loss: 1.5815 - val_accuracy: 0.5355\n",
            "Epoch 17/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.5546 - accuracy: 0.8780 - val_loss: 1.9933 - val_accuracy: 0.4723\n",
            "Epoch 18/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 0.4985 - accuracy: 0.8993 - val_loss: 2.0989 - val_accuracy: 0.4728\n",
            "Epoch 19/20\n",
            "898/898 [==============================] - 10s 11ms/step - loss: 0.4428 - accuracy: 0.9182 - val_loss: 2.9349 - val_accuracy: 0.3683\n",
            "Epoch 20/20\n",
            "898/898 [==============================] - 10s 11ms/step - loss: 0.3970 - accuracy: 0.9356 - val_loss: 2.1665 - val_accuracy: 0.4923\n",
            "Epoch 1/20\n",
            "898/898 [==============================] - 10s 10ms/step - loss: 1.8377 - accuracy: 0.3533 - val_loss: 1.8079 - val_accuracy: 0.3820\n",
            "Epoch 2/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.6507 - accuracy: 0.4434 - val_loss: 1.7445 - val_accuracy: 0.4026\n",
            "Epoch 3/20\n",
            "898/898 [==============================] - 10s 11ms/step - loss: 1.5455 - accuracy: 0.4873 - val_loss: 1.5734 - val_accuracy: 0.4675\n",
            "Epoch 4/20\n",
            "898/898 [==============================] - 12s 14ms/step - loss: 1.4645 - accuracy: 0.5153 - val_loss: 2.2082 - val_accuracy: 0.3541\n",
            "Epoch 5/20\n",
            "898/898 [==============================] - 10s 12ms/step - loss: 1.3974 - accuracy: 0.5416 - val_loss: 1.6543 - val_accuracy: 0.4255\n",
            "Epoch 6/20\n",
            "898/898 [==============================] - 8s 9ms/step - loss: 1.3362 - accuracy: 0.5658 - val_loss: 1.8938 - val_accuracy: 0.3505\n",
            "Epoch 7/20\n",
            "898/898 [==============================] - 9s 10ms/step - loss: 1.2756 - accuracy: 0.5924 - val_loss: 1.9323 - val_accuracy: 0.4129\n",
            "Epoch 8/20\n",
            "812/898 [==========================>...] - ETA: 0s - loss: 1.2152 - accuracy: 0.6131"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Save the best model\n",
        "best_model.save('/content/drive/MyDrive/ML Project/data/best_resnet_hptuning_02.h5')"
      ],
      "metadata": {
        "id": "YwdJVIVJqbiL"
      },
      "id": "YwdJVIVJqbiL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "best_resnet_hptuning = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "best_resnet_hptuning.fit(\n",
        "    train_imgs, \n",
        "    train_lbls, \n",
        "    epochs=20, \n",
        "    batch_size=32, \n",
        "    validation_data=(val_imgs, val_lbls)\n",
        ")"
      ],
      "metadata": {
        "id": "5Mweyb4gwA1N"
      },
      "id": "5Mweyb4gwA1N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V89E5Cf_wF53"
      },
      "id": "V89E5Cf_wF53",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-8.m108",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2d5ba12f-1436-4c49-a095-b58e06f5b79c",
        "hbsaDQu9AIGf"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}